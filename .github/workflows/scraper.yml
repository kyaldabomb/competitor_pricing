name: Run Web Scrapers

on:
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC
  workflow_dispatch:
    inputs:
      scraper:
        description: 'Scraper to run (leave empty to run all)'
        required: false
        default: ''

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
      EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install Chrome and Selenium dependencies
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable chromium-driver
          
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openpyxl requests beautifulsoup4 selenium selenium-stealth webdriver-manager send2trash
          pip install "lxml[html_clean]"
          pip install requests-html
          
      - name: Test FTP connection
        run: python test_ftp.py
          
      - name: Download files from FTP
        run: |
          if [ -n "${{ github.event.inputs.scraper }}" ]; then
            python download_files.py ${{ github.event.inputs.scraper }}
          else
            python download_files.py
          fi
          
      - name: Run scrapers
        run: |
          if [ -n "${{ github.event.inputs.scraper }}" ]; then
            python $SCRAPER_SCRIPT ${{ github.event.inputs.scraper }}
            exit_code=$?
            if [ $exit_code -ne 0 ]; then
              echo "Scraper failed with exit code $exit_code"
              exit $exit_code
            fi
          else
            for scraper in Belfield Sky_Music sounds_easy acoustic_centre apw billy_hyde better derringer dj_city mannys; do
              echo "Running $scraper scraper..."
              python ${scraper}_Daily_Modified.py $scraper
              exit_code=$?
              if [ $exit_code -ne 0 ]; then
                echo "$scraper scraper failed with exit code $exit_code"
                # Continue with other scrapers even if one fails
              fi
            done
          fi
        
      - name: Upload results to FTP
        run: |
          if [ -n "${{ github.event.inputs.scraper }}" ]; then
            python upload_files.py ${{ github.event.inputs.scraper }}
          else
            python upload_files.py
          fi
