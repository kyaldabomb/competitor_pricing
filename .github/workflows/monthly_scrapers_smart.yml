name: Run Monthly Web Scrapers (Smart)
on:
  schedule:
    - cron: '0 0 1 * *'  # Run at midnight on the 1st day of each month
  workflow_dispatch:
    inputs:
      scraper:
        description: 'Monthly scraper to run (leave empty to run all)'
        required: false
        default: ''
      chunk:
        description: 'Chunk number (0 for normal run, 1+ for chunked)'
        required: false
        default: '0'

jobs:
  # Job 1: Run all normal scrapers and chunk 1 of long scrapers
  scrape_main:
    runs-on: ubuntu-latest
    timeout-minutes: 350  # Just under 6 hours
    env:
      FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
      EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install Chrome and Selenium dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          sudo ln -sf /usr/bin/google-chrome-stable /usr/bin/google-chrome
          google-chrome --version
          
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openpyxl requests beautifulsoup4 selenium selenium-stealth webdriver-manager send2trash
          pip install "lxml[html_clean]"
          
      - name: Test FTP connection
        run: python test_ftp.py
          
      - name: Download files from FTP
        run: |
          if [ -n "${{ github.event.inputs.scraper }}" ]; then
            python download_files.py ${{ github.event.inputs.scraper }}
          else
            python download_files.py --type monthly
          fi
          
      - name: Run scrapers
        timeout-minutes: 340
        run: |
          if [ -n "${{ github.event.inputs.scraper }}" ] && [ "${{ github.event.inputs.chunk }}" != "0" ]; then
            # Run specific scraper with specific chunk
            echo "Running ${{ github.event.inputs.scraper }} chunk ${{ github.event.inputs.chunk }}"
            python run_scrapers.py --type monthly --chunk ${{ github.event.inputs.chunk }}
          elif [ -n "${{ github.event.inputs.scraper }}" ]; then
            # Run specific scraper normally
            echo "Running specific scraper: ${{ github.event.inputs.scraper }}"
            python "${{{ github.event.inputs.scraper }}}_Monthly_Modified.py" ${{ github.event.inputs.scraper }}
          else
            # Run all scrapers normally (non-chunked) and chunk 1 of chunked scrapers
            echo "Running all non-chunked scrapers..."
            python run_scrapers.py --type monthly --chunk 0
            
            echo "Running chunk 1 of chunked scrapers..."
            python run_scrapers.py --type monthly --chunk 1
          fi
      
      - name: Upload files as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pricing-spreadsheets-main
          path: Pricing Spreadsheets/*.xlsx
        if: always()
        
      - name: Upload results to FTP
        run: |
          if [ -n "${{ github.event.inputs.scraper }}" ]; then
            python upload_files.py ${{ github.event.inputs.scraper }}
          else
            python upload_files.py --type monthly
          fi

  # Job 2: Run chunk 2 of long scrapers (if needed)
  scrape_chunk2:
    needs: scrape_main  # Run after main job completes
    runs-on: ubuntu-latest
    timeout-minutes: 350
    # Only run if this is the scheduled monthly run (not manual)
    if: github.event_name == 'schedule' || github.event.inputs.chunk == '0'
    env:
      FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
      EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install Chrome and Selenium dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          sudo ln -sf /usr/bin/google-chrome-stable /usr/bin/google-chrome
          
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openpyxl requests beautifulsoup4 selenium selenium-stealth webdriver-manager send2trash
          pip install "lxml[html_clean]"
          
      - name: Download latest files from FTP (with chunk1 updates)
        run: python download_files.py --type monthly
          
      - name: Run chunk 2 of chunked scrapers
        timeout-minutes: 340
        run: |
          echo "Running chunk 2 of chunked scrapers..."
          python run_scrapers.py --type monthly --chunk 2
      
      - name: Upload files as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pricing-spreadsheets-chunk2
          path: Pricing Spreadsheets/*.xlsx
        if: always()
        
      - name: Upload final results to FTP
        run: python upload_files.py --type monthly
